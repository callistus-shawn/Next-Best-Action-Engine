{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4381,"sourceType":"datasetVersion","datasetId":2637},{"sourceId":9055370,"sourceType":"datasetVersion","datasetId":5390522},{"sourceId":12322459,"sourceType":"datasetVersion","datasetId":7767305}],"dockerImageVersionId":30299,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-29T20:06:20.502183Z","iopub.execute_input":"2025-06-29T20:06:20.502515Z","iopub.status.idle":"2025-06-29T20:06:20.520230Z","shell.execute_reply.started":"2025-06-29T20:06:20.502487Z","shell.execute_reply":"2025-06-29T20:06:20.519131Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/reddit-mbti-dataset/unique_author.csv\n/kaggle/input/reddit-mbti-dataset/reddit_post.csv\n/kaggle/input/mbti-type/mbti_1.csv\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/reddit-mbti-dataset/reddit_post.csv\")","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:46:00.113308Z","iopub.execute_input":"2025-06-29T19:46:00.114251Z","iopub.status.idle":"2025-06-29T19:47:00.238555Z","shell.execute_reply.started":"2025-06-29T19:46:00.114203Z","shell.execute_reply":"2025-06-29T19:47:00.237795Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"data=data.head(5000)\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:47:00.240380Z","iopub.execute_input":"2025-06-29T19:47:00.241024Z","iopub.status.idle":"2025-06-29T19:47:00.258667Z","shell.execute_reply.started":"2025-06-29T19:47:00.240986Z","shell.execute_reply":"2025-06-29T19:47:00.257972Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"             author                                               body  mbti\n0    LadyBanterbury                              lol thats why i left   INFP\n1           Finarin  i was just about to post i try telling people ...  INTP\n2         xanplease  my first thought was pepsi or something probab...  INFP\n3   HeirToGallifrey  not if the formula is something like every tim...  ENTP\n4  ElementalVoltage  well i wouldnt know but i think theres a lot o...  INTP","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>body</th>\n      <th>mbti</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LadyBanterbury</td>\n      <td>lol thats why i left</td>\n      <td>INFP</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Finarin</td>\n      <td>i was just about to post i try telling people ...</td>\n      <td>INTP</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>xanplease</td>\n      <td>my first thought was pepsi or something probab...</td>\n      <td>INFP</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HeirToGallifrey</td>\n      <td>not if the formula is something like every tim...</td>\n      <td>ENTP</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ElementalVoltage</td>\n      <td>well i wouldnt know but i think theres a lot o...</td>\n      <td>INTP</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"types = np.unique(data.mbti.values)\ntypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:47:00.259561Z","iopub.execute_input":"2025-06-29T19:47:00.259833Z","iopub.status.idle":"2025-06-29T19:47:00.270656Z","shell.execute_reply.started":"2025-06-29T19:47:00.259796Z","shell.execute_reply":"2025-06-29T19:47:00.269754Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"array(['ENFJ', 'ENFP', 'ENTJ', 'ENTP', 'ESFJ', 'ESFP', 'ESTJ', 'ESTP',\n       'INFJ', 'INFP', 'INTJ', 'INTP', 'ISFJ', 'ISFP', 'ISTJ', 'ISTP'],\n      dtype=object)"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"def get_type_index(string):\n    return list(types).index(string)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:47:00.272562Z","iopub.execute_input":"2025-06-29T19:47:00.272879Z","iopub.status.idle":"2025-06-29T19:47:00.279185Z","shell.execute_reply.started":"2025-06-29T19:47:00.272799Z","shell.execute_reply":"2025-06-29T19:47:00.278326Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"data['type_index'] = data['mbti'].apply(get_type_index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:47:00.280231Z","iopub.execute_input":"2025-06-29T19:47:00.280521Z","iopub.status.idle":"2025-06-29T19:47:00.297422Z","shell.execute_reply.started":"2025-06-29T19:47:00.280498Z","shell.execute_reply":"2025-06-29T19:47:00.296684Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"data.body.values[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:47:00.298479Z","iopub.execute_input":"2025-06-29T19:47:00.298792Z","iopub.status.idle":"2025-06-29T19:47:00.305431Z","shell.execute_reply.started":"2025-06-29T19:47:00.298761Z","shell.execute_reply":"2025-06-29T19:47:00.304520Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'lol thats why i left '"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"import string\nimport re\n\ndef clean_text(text):\n    regex = re.compile('[%s]' % re.escape('|'))\n    text = regex.sub(\" \", text)\n    words = str(text).split()\n    words = [i.lower() + \" \" for i in words]\n    words = [i for i in words if not \"http\" in i]\n    words = \" \".join(words)\n    words = words.translate(words.maketrans('', '', string.punctuation))\n    return words\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:47:00.306331Z","iopub.execute_input":"2025-06-29T19:47:00.306564Z","iopub.status.idle":"2025-06-29T19:47:00.313417Z","shell.execute_reply.started":"2025-06-29T19:47:00.306542Z","shell.execute_reply":"2025-06-29T19:47:00.312564Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"data['cleaned_text'] = data['body'].apply(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:47:00.314391Z","iopub.execute_input":"2025-06-29T19:47:00.314626Z","iopub.status.idle":"2025-06-29T19:47:00.410879Z","shell.execute_reply.started":"2025-06-29T19:47:00.314605Z","shell.execute_reply":"2025-06-29T19:47:00.410241Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"data.cleaned_text.values[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:47:00.411812Z","iopub.execute_input":"2025-06-29T19:47:00.412113Z","iopub.status.idle":"2025-06-29T19:47:00.417985Z","shell.execute_reply.started":"2025-06-29T19:47:00.412086Z","shell.execute_reply":"2025-06-29T19:47:00.417109Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'lol  thats  why  i  left '"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:47:00.421092Z","iopub.execute_input":"2025-06-29T19:47:00.421590Z","iopub.status.idle":"2025-06-29T19:47:00.430774Z","shell.execute_reply.started":"2025-06-29T19:47:00.421552Z","shell.execute_reply":"2025-06-29T19:47:00.430012Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"             author                                               body  mbti  \\\n0    LadyBanterbury                              lol thats why i left   INFP   \n1           Finarin  i was just about to post i try telling people ...  INTP   \n2         xanplease  my first thought was pepsi or something probab...  INFP   \n3   HeirToGallifrey  not if the formula is something like every tim...  ENTP   \n4  ElementalVoltage  well i wouldnt know but i think theres a lot o...  INTP   \n\n   type_index                                       cleaned_text  \n0           9                          lol  thats  why  i  left   \n1          11  i  was  just  about  to  post  i  try  telling...  \n2           9  my  first  thought  was  pepsi  or  something ...  \n3           3  not  if  the  formula  is  something  like  ev...  \n4          11  well  i  wouldnt  know  but  i  think  theres ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n      <th>body</th>\n      <th>mbti</th>\n      <th>type_index</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LadyBanterbury</td>\n      <td>lol thats why i left</td>\n      <td>INFP</td>\n      <td>9</td>\n      <td>lol  thats  why  i  left</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Finarin</td>\n      <td>i was just about to post i try telling people ...</td>\n      <td>INTP</td>\n      <td>11</td>\n      <td>i  was  just  about  to  post  i  try  telling...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>xanplease</td>\n      <td>my first thought was pepsi or something probab...</td>\n      <td>INFP</td>\n      <td>9</td>\n      <td>my  first  thought  was  pepsi  or  something ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HeirToGallifrey</td>\n      <td>not if the formula is something like every tim...</td>\n      <td>ENTP</td>\n      <td>3</td>\n      <td>not  if  the  formula  is  something  like  ev...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ElementalVoltage</td>\n      <td>well i wouldnt know but i think theres a lot o...</td>\n      <td>INTP</td>\n      <td>11</td>\n      <td>well  i  wouldnt  know  but  i  think  theres ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"data=data.drop('author', axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:47:00.431885Z","iopub.execute_input":"2025-06-29T19:47:00.432241Z","iopub.status.idle":"2025-06-29T19:47:00.441758Z","shell.execute_reply.started":"2025-06-29T19:47:00.432202Z","shell.execute_reply":"2025-06-29T19:47:00.440968Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(data)\ntrain, val = train_test_split(train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:47:00.442980Z","iopub.execute_input":"2025-06-29T19:47:00.443294Z","iopub.status.idle":"2025-06-29T19:47:00.918571Z","shell.execute_reply.started":"2025-06-29T19:47:00.443262Z","shell.execute_reply":"2025-06-29T19:47:00.917862Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import tensorflow as tf\none_hot_labels = tf.keras.utils.to_categorical(train.type_index.values, num_classes=16)\nval_labels= tf.keras.utils.to_categorical(val.type_index.values, num_classes=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:49:14.976636Z","iopub.execute_input":"2025-06-29T19:49:14.977353Z","iopub.status.idle":"2025-06-29T19:49:19.933037Z","shell.execute_reply.started":"2025-06-29T19:49:14.977320Z","shell.execute_reply":"2025-06-29T19:49:19.932305Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import transformers\ntokenizer = transformers.AutoTokenizer.from_pretrained('bert-base-uncased')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"maxlen = 256\n\ntrain_input_ids = [tokenizer.encode(str(i), max_length = maxlen , pad_to_max_length = True) for i in train.cleaned_text.values]\nval_input_ids = [tokenizer.encode(str(i), max_length = maxlen , pad_to_max_length = True) for i in val.cleaned_text.values]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:49:26.675707Z","iopub.execute_input":"2025-06-29T19:49:26.676042Z","iopub.status.idle":"2025-06-29T19:49:27.673796Z","shell.execute_reply.started":"2025-06-29T19:49:26.676017Z","shell.execute_reply":"2025-06-29T19:49:27.672944Z"}},"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"def create_model(): \n    input_word_ids = tf.keras.layers.Input(shape=(maxlen,), dtype=tf.int32,\n                                           name=\"input_word_ids\")\n    bert_layer = transformers.TFBertModel.from_pretrained('bert-base-uncased')\n    bert_outputs = bert_layer(input_word_ids)[0]\n    pred = tf.keras.layers.Dense(16, activation='softmax')(bert_outputs[:,0,:])\n    \n    model = tf.keras.models.Model(inputs=input_word_ids, outputs=pred)\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(\n    learning_rate=0.00001), metrics=['accuracy'])\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:49:28.380616Z","iopub.execute_input":"2025-06-29T19:49:28.381658Z","iopub.status.idle":"2025-06-29T19:49:28.389686Z","shell.execute_reply.started":"2025-06-29T19:49:28.381616Z","shell.execute_reply":"2025-06-29T19:49:28.388739Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import tensorflow as tf\nuse_tpu = False\nif use_tpu:\n    # Create distribution strategy\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n    # Create model\n    with strategy.scope():\n        model = create_model()\nelse:\n    model = create_model()\n    \nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T19:49:29.813496Z","iopub.execute_input":"2025-06-29T19:49:29.814317Z","iopub.status.idle":"2025-06-29T19:49:55.427448Z","shell.execute_reply.started":"2025-06-29T19:49:29.814283Z","shell.execute_reply":"2025-06-29T19:49:55.426516Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72b6deed111449e2879ff8caca7b8435"}},"metadata":{}},{"name":"stderr","text":"Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_word_ids (InputLayer)  [(None, 256)]             0         \n_________________________________________________________________\ntf_bert_model (TFBertModel)  TFBaseModelOutputWithPool 109482240 \n_________________________________________________________________\ntf.__operators__.getitem (Sl (None, 768)               0         \n_________________________________________________________________\ndense (Dense)                (None, 16)                12304     \n=================================================================\nTotal params: 109,494,544\nTrainable params: 109,494,544\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"batch_size = 6\n\nmodel.fit(np.array(train_input_ids), one_hot_labels,validation_data = (np.array(val_input_ids), val_labels),\n          verbose = 1, epochs = 10, batch_size = batch_size,  callbacks = [tf.keras.callbacks.EarlyStopping(patience = 8)])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"bertcls\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T20:06:34.148993Z","iopub.execute_input":"2025-06-29T20:06:34.149306Z","iopub.status.idle":"2025-06-29T20:07:18.411612Z","shell.execute_reply.started":"2025-06-29T20:06:34.149283Z","shell.execute_reply":"2025-06-29T20:07:18.410691Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"!zip -r model2.zip bertcls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T20:08:40.387633Z","iopub.execute_input":"2025-06-29T20:08:40.388081Z","iopub.status.idle":"2025-06-29T20:09:40.242465Z","shell.execute_reply.started":"2025-06-29T20:08:40.388023Z","shell.execute_reply":"2025-06-29T20:09:40.241515Z"}},"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n  adding: bertcls/ (stored 0%)\n  adding: bertcls/assets/ (stored 0%)\n  adding: bertcls/variables/ (stored 0%)\n  adding: bertcls/variables/variables.data-00000-of-00001 (deflated 16%)\n  adding: bertcls/variables/variables.index (deflated 81%)\n  adding: bertcls/keras_metadata.pb (deflated 95%)\n  adding: bertcls/saved_model.pb (deflated 92%)\n","output_type":"stream"}],"execution_count":26}]}